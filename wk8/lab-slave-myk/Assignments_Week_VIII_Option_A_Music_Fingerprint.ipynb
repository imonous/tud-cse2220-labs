{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f1e4a92",
   "metadata": {},
   "source": [
    "# Assignments Week VIII.<br><br>Signal Processing in Action Option A: Music Fingerprint\n",
    "<hr style=\"height:1px; border:none; background-color:blue;\">\n",
    "\n",
    "<p style=\"color: #ee5353;\"> For Week VIII there are two options: either option A or option B. <i>You only need to complete one of these for the mandatory assignments.</i></p>\n",
    "\n",
    "### Useful Information\n",
    "\n",
    "**In this notebook you will be working on the mandatory assignments for week eight of Signal Processing**. In order to complete the notebook you must complete all of the necessary code blocks (labelled with \"Write your code here\"), and fill in all answer blocks. Each section of the notebook will state the completion criteria, which summarize everything you need to do to complete that section. **If you are stuck on a section in this notebook, it may be beneficial to check the non-mandatory exercises for this week, since they may have content that can help you!**\n",
    "\n",
    "Mandatory assignments are pass or fail. **If your notebook is incomplete - meaning you did not complete the task required or answer the necessary questions - then you will automatically fail.** So once you finish this notebook, please look through it to make sure you've answered everything!\n",
    "\n",
    "<hr style=\"height:1px; border:none; background-color:blue;\">\n",
    "\n",
    "### Objectives\n",
    "- Experience the use of spectra/DFT in real-world computer science applications.\n",
    "- Learn how to extract relevant features from spectra/DFTs.\n",
    "- Understand perceptual aspects of signal processing.\n",
    "\n",
    "<br>\n",
    "<hr style=\"height:3px; border:none; background-color:blue;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b50b56",
   "metadata": {},
   "source": [
    "<h3 style=\"color:blue;\"> <u>Imports for Exercises and Assignments </u></h3> \n",
    "\n",
    "Run the code below to import modules that will be used throughout the rest of this notebook.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58cadd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Import various modules into PYTHON. These will be used throughput this Jupyter Notebook\n",
    "##########################################################################################\n",
    "# import matplotlib for data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import NumPy for better matrix support\n",
    "import numpy as np\n",
    "\n",
    "# import Pickle for data serialisation\n",
    "import pickle as pkl\n",
    "\n",
    "# import wav for reading files\n",
    "from scipy.io import wavfile as wv\n",
    "\n",
    "# import audio for playing audio\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# add path for importing modules to './data'. \n",
    "import sys\n",
    "sys.path.insert(0, './data')\n",
    "\n",
    "#######################################################################################\n",
    "#\n",
    "# function for easy plotting of signals with centered axis and larger figure\n",
    "#\n",
    "#   nicesignalplot(scale,values,caption)\n",
    "#      scale:   array with vertical scale values 't' (float)\n",
    "#      values:  array with signal values 'x(t)' to plot (float or complex, \n",
    "#               in latter case .real will be used)\n",
    "#      caption: caption of the plot (string)\n",
    "#\n",
    "######################################################################################\n",
    "def nicesignalplot(scale,values,caption):\n",
    "    myfigure  =  plt.figure(figsize=(15,7.5))\n",
    "    ax        = myfigure.add_subplot(1, 1, 1)\n",
    "# Move left y-axis and bottim x-axis to centre, passing through (0,0)\n",
    "    ax.spines['left'].set_position('zero')\n",
    "    ax.spines['bottom'].set_position('zero')\n",
    "# Eliminate upper and right axes\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "# Show ticks in the left and lower axes only\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    plt.plot( scale, values)\n",
    "    plt.title('(nicesignalplot): '+caption)\n",
    "    plt.show()\n",
    "\n",
    "###########################################################################################\n",
    "#\n",
    "# function for easy plotting of DFT magnitude spectrum with centered axis and larger figure\n",
    "#\n",
    "#      nicemagspecplot(N,dftvalues,caption,hvsize, [ylabel] )\n",
    "#      N:          number of samples in x[n] and X[k], is equal to the applied DFT length\n",
    "#      dftvalues:  array with complex-valued DFT coefficient X[k].\n",
    "#      caption: caption of the plot (string)\n",
    "#      hvsize = [hsize,vsize]: array with horizontal width and vertical height of plot. \n",
    "#                              Try hvsize = [7,4]\n",
    "#      ylabel = optional string for naming vertical axis. Default is |X(ω)|.\n",
    "#\n",
    "##########################################################################################\n",
    "def nicemagspecplot(N,dftvalues,caption,hvsize,ylabel='$|X(\\hat{\\omega})|$'):\n",
    "    myfigure  = plt.figure(figsize=hvsize)\n",
    "    ax        = myfigure.add_subplot(1, 1, 1)\n",
    "# Move left y-axis and bottim x-axis to centre, passing through (0,0)\n",
    "    ax.spines['left'].set_position('zero')\n",
    "    ax.spines['bottom'].set_position('zero')\n",
    "# Eliminate upper and right axes\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "# Show ticks in the left and lower axes only\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    ax.stem(np.arange(N) * (2 * np.pi / N), np.abs(dftvalues))\n",
    "    plt.title('(nicemagspecplot): '+caption)\n",
    "    plt.xlabel('$\\hat{\\omega}$',fontsize=16,horizontalalignment='right',x=0.95)\n",
    "    plt.ylabel(ylabel,fontsize=16,horizontalalignment='right',y=0.95)\n",
    "    plt.show()\n",
    "    \n",
    "########################################################################################\n",
    "#\n",
    "# function for easy plotting of DFT phase spectrum with centered axis and larger figure\n",
    "#\n",
    "#      nicephasespecplot(N,dftvalues,caption,hvsize, [ylabel] )\n",
    "#      N:          number of samples in x[n] and X[k], is equal to the applied DFT length\n",
    "#      dftvalues:  array with complex-valued DFT coefficient X[k].\n",
    "#      caption:    caption of the plot (string)\n",
    "#      hvsize = [hsize,vsize]: array with horizontal width and vertical height of plot. \n",
    "#                              Try hvsize = [7,4]\n",
    "#      ylabel = optional string for naming vertical axis. Default is arg(X(ω)).\n",
    "#\n",
    "#########################################################################################\n",
    "def nicephasespecplot(N,dftvalues,caption,hvsize,ylabel='arg$(X(\\hat{\\omega}))$'):\n",
    "    myfigure  = plt.figure(figsize=hvsize)\n",
    "    ax        = myfigure.add_subplot(1, 1, 1)\n",
    "# Move left y-axis and bottim x-axis to centre, passing through (0,0)\n",
    "    ax.spines['left'].set_position('zero')\n",
    "    ax.spines['bottom'].set_position('zero')\n",
    "# Eliminate upper and right axes\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "# Show ticks in the left and lower axes only\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    ax.stem(np.arange(N) * (2 * np.pi / N), np.angle(dftvalues))\n",
    "    plt.title('(nicephasespecplot): '+caption)\n",
    "    plt.xlabel('$\\hat{\\omega}$',fontsize=16,horizontalalignment='right',x=0.95)\n",
    "    plt.ylabel(ylabel,fontsize=16,horizontalalignment='right',y=0.95)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2026c512",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px; border:none; background-color:blue;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae17524",
   "metadata": {},
   "source": [
    "<!---PYTHON ASSIGNMENT VI.1 ---------------------------------------------------------------------->\n",
    "\n",
    " \n",
    "<h3 style=\"color:blue;\"> <u>Python Hands-on Assignment VIII.1: Music compression, the essence of MP3</u></h3>  \n",
    "    \n",
    "<br>\n",
    "<div style=\"background-color:#c2eafa\">\n",
    "<br>\n",
    "<b>Completion requirements for this assigment.</b>\n",
    "<ul>\n",
    "<li>Explain how the choice of $L$ relates to the factor of compression.</li>\n",
    "<li>Show and explain the pseudocolor plot of the retained non-zero DFT coefficients for three different choices of $L$.</li>\n",
    "<li>Find out which value of $L$ gives an acceptable audio quality on the given audio sample.</li>\n",
    "<li>Explain to what extent the choice of $L$ affects audio quality on two different audio samples.\n",
    "</ul>\n",
    "<hr>\n",
    "</div>\n",
    "\n",
    "We explore the principles of today’s compression algorithms such as mp3, jpeg, and the different mpeg video compression standards. The fundamental observation in all compression methods is that if a signal (music, image, video) is represented in a spectral form (i.e. in the frequency transform domain), many transform coefficient are very small and could be ignored. Hence fewer transform coefficients than samples in the original signal are needed to still get a decent perceptual quality. In most compression standards, a variation on the DFT is used, namely the DCT or Discrete Cosine Transform. In this assignment, we will use the DFT/FFT for the purpose of simplicity.\n",
    "\n",
    "**Read the music file `data/musicclip.wav` into the array named `mmdata`, and listen to the 10 seconds of music.**\n",
    "\n",
    "Note: If you're stuck, referring to the exercises for this week will likely help.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7568a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f64145",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**What is the sampling frequency of the music?**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f06794",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Your answer goes here.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a9efab",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Most compression algorithms work with time segments (frames) or spatial segment (for instance image blocks). We therefore break up the audio into short non-overlapping frames, so that we can process each frame independently. We use as frame length of $N=512$ samples. \n",
    "\n",
    "**Convert the audio signal to frames, following the procedure of Python exercise VIII.1. Since we are going to process each frame in the Fourier domain, compute for each frame the DFT. Name the resulting 2-D array of DFT-ed frames `MMFRAMES`.**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb1605",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**What is the length in seconds of each frame?**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a798c9f2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Your answer goes here.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b739da63",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We now have the signal available as a collection of spectra computed on a frame-by-frame basis.  Remember that for an $N$-point DFT, we obtain $N/2+1$ unique DFT coefficients, the other $N/2-1$ coefficients can be recovered because of the complex-conjugated symmetry of the spectum. However, whereas each signal samples is real-valued, the DFT coefficients are complex numbers requiring the storage of 2 numbers (real and imaginary part) per DFT coefficient. It seems therefore that in total we have $2.(N/2+1) = N+2 $ numbers to store instead of $N$ samples. However, the DFT coefficient 0 and $N/2$ are always real-valued, ending up with exactly $N$ numbers to store.\n",
    "\n",
    "**For each frame-based spectrum in `MMFRAMES` we will keep only the $L$ largest DFT coefficients in the range $[0, \\cdots, \\pi] \\equiv [0,\\cdots,N/2]$, and ignore all other DFT coefficients by making them zero. What is the factor of compression if we keep only the $L=8$ largest DFT coefficient?**\n",
    "\n",
    "**Find for each frame the $L$ DFT coefficients that have the largest magnitude in the range $[0,N/2]$.** A suitable Python function is, for instance, `indices=np.argsort()`. **Maintain only these $L$ largest original DFT coefficients, and set all other DFT coefficients to zero.** Notice that each frame will have the largest DFT coefficients in different positions. For instance, in frame 0 the largest two DFT coeffients might be in position 0 and 3, and in frame 1 in position 2 and 8. **Store the resulting DFT spectra (with now many zero DFT coefficients) in a 2-D array named `CMFRAMES`.**\n",
    "\n",
    "Notice that you also have to deal with the DFT coefficients in the range $[N/2+1, N-1]$. For instance, if you make DFT-coefficient 2 equal to zero, then also DFT-coefficient $N-2=510$ must be made equal to zero to maintain the symmetry property of the spectrum. **An easy way to solve this is by keeping the $2*L-1$ largest DFT coefficients in the range $[0,N-1]$. Explain why this solution will work.**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b8a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2163a45",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Please answer the two following question:**\n",
    "<ul>\n",
    "    <li>What is the factor of compression if we keep only the $L=8$ largest DFT coefficient? </li>\n",
    "    <li>Additionally, it is claimed that an easy way to maintain symmetry of the spectrum is to keep the $2*L-1$ largest DFT coefficients in the range $[0,N-1]$. Explain why this solution will work.</li>\n",
    "</ul>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b34ee7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Your answer goes here.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53156cc1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The 2-D array `CMFRAMES` contains a compressed version of the music signal, where each frame in the DFT domain is represented by only $L$ non-zero DFT coefficients (plus the corresponding complex conjugated DFT values), rather than all original DFT coefficients.\n",
    "\n",
    "**An easy way to visualize which non-zero DFT coefficients are maintained is by using a pseudo-color plot of the array `CMFRAMES`.** Use the Python command `plt.pcolor(np.log(np.abs(CMFRAMES[0:100,:int(Nframelen/8)].T)+0.001))` to **display the first 512/8 = 128 DFT coefficients of the first 100 frames of the 2-D array `CMFRAMES`.** Different pseudo-colors indicate different magnitude/size of DFT coefficients in a frame.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c5dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c000875",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Study and describe the effect of using three different values of $L$. Make sure to display the plot for each value of $L$. Where are the largest DFT coefficients usually located in the spectrum? Are the same DFT coefficients selected in each frame?**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d090b7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Your answer goes here.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fadac8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Carry out an inverse DFT/FFT on each frame of CMFRAMES. Reshape the resulting array of compressed frames into a 1-D audio signal. Listen to the resulting compressed music for different values of $L$.**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe5059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3201591",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Determine which value of $L$ gives an acceptable audio quality and explain why. How large is the compression factor in this case?**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c50a147",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Your answer goes here.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf96ba9e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Use the compression method that you have implemented in this assignment on other music files** (some are provided in the data set, or you can bring your own music samples), **and on the short speech segment `data/welkom.wav`. Study and describe the effect on the quality of setting different values of $L$.**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a66a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e59c6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Your answer goes here.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17deb9",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px; border:none; background-color:blue;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef95cc",
   "metadata": {},
   "source": [
    "<!---PYTHON ASSIGNMENT VIII.2 ---------------------------------------------------------------------->\n",
    "  \n",
    "<h3 style=\"color:blue;\"> <u>Python Hands-on Assignment VIII.2:  Music identification, at the core of Shazam & more</u></h3>  \n",
    "  \n",
    "<br>\n",
    "<div style=\"background-color:#c2eafa\">\n",
    "<br>\n",
    "<b>Completion requirements for this assigment.</b>\n",
    "<ul>\n",
    "<li>Show the fingerprints for one of the given music samples.</li>\n",
    "<li>Determine which song is represented by the fingerprint `data/fingerprint.pkl`. Show the BER for each of the music clips in relation to the unknown music clip.</li>\n",
    "<li>Explain how you would set a BER threshold to recognize a song in the given dataset..</li>\n",
    "</ul>\n",
    "<hr>\n",
    "</div>\n",
    "\n",
    "**In this assignment you will implement the basics of online music identification services such as Shazam, SoundHound, Tunatic, and Nabbit.** Music identification is based on comparing the spectrum of the query music to a database of spectra of known songs. The best matching spectrum determines which song is identified. Online music identification often involves identifying songs independently of the specific recording device, performance, artist, or even versions of the song. Here, we will focus on the problem that involves different versions of the same reference recording.\n",
    "\n",
    "Like the compression in previous assignment, music identification is based on processing short frames of music. The way these frames are selected and which frequencies are represented in the spectrum is critical to the success of music identification. In this assignment we will take the simplest case and ignore many practical engineering issues.\n",
    "\n",
    "Rather than storing the spectrum of the songs, a highly compact binary representation is derived from the spectrum and stored, usually called the <i>fingerprint</i> of the music. In this assignment you are given a precomputed audio-fingerprint and 25 songs (actually 5 different songs, plus 4 degraded versions of each song). The challenge is to determine which of the song(s) correspond(s) to the given fingerprint.\n",
    "\n",
    "**The following songs are given to you; all songs have a sampling rate of 22.05 kHz, and are stored as wav-files in the directory `data/querysongs`.** The compression of the files indicated by `_4` and `_5` has been done with the technique of Python assignment VIII.1.\n",
    "\n",
    "![PA.VII.2%28i%29.png](graphics/PA.VII.2%28i%29.png)\n",
    "\n",
    "**The music identification that we develop operates with non-overlapping frames of $N=512$ samples each. If you have not done so, carry out Python exercise VIII.1, such that you can convert any of the above songs into a $M \\times N$ array `xx`.** For the purpose of this assignment, `N=512` (the DFT/FFT will be over $N = 512$ samples) and `M = 257` (we have 257 non-overlapping frames). These array dimensions match exactly with the number of samples (namely, 131584 samples) in the audio files. \n",
    "\n",
    "**Load one of the audio files into `xx`, listen to the music, convert the music into an array of $M$ frames,  each of length $N$. Apply the DFT to each frame to obtain a spectrum per frame, stored as the array `XX`.** The fingerprints of the songs will be computed on the magnitude spectrum of each frame. Therefore **compute the magnitude of the spectum per frame. Display the resulting spectrogram using a pseudo-color plot.**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f89e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n",
    "musicfiles = ['data/querysongs/query_call_me_1.wav','data/querysongs/query_call_me_2.wav',\\\n",
    "              'data/querysongs/query_call_me_3.wav','data/querysongs/query_call_me_4.wav',\\\n",
    "              'data/querysongs/query_call_me_5.wav',\\\n",
    "              'data/querysongs/query_get_lucky_1.wav','data/querysongs/query_get_lucky_2.wav',\\\n",
    "              'data/querysongs/query_get_lucky_3.wav','data/querysongs/query_get_lucky_4.wav',\\\n",
    "              'data/querysongs/query_get_lucky_5.wav',\\\n",
    "              'data/querysongs/query_scream_shout_1.wav','data/querysongs/query_scream_shout_2.wav',\\\n",
    "              'data/querysongs/query_scream_shout_3.wav','data/querysongs/query_scream_shout_4.wav',\\\n",
    "              'data/querysongs/query_scream_shout_5.wav',\\\n",
    "              'data/querysongs/query_locked_out_1.wav','data/querysongs/query_locked_out_2.wav',\\\n",
    "              'data/querysongs/query_locked_out_3.wav','data/querysongs/query_locked_out_4.wav',\\\n",
    "              'data/querysongs/query_locked_out_5.wav',\\\n",
    "              'data/querysongs/query_blurred_lines_1.wav','data/querysongs/query_blurred_lines_2.wav',\\\n",
    "              'data/querysongs/query_blurred_lines_3.wav','data/querysongs/query_blurred_lines_4.wav',\\\n",
    "              'data/querysongs/query_blurred_lines_5.wav']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36f5ec",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Rather than working with the magnitudes of the individual DFT/FFT coefficients, the coefficients are grouped together into 17 bands according to the so-called Bark-scale. The Bark-scale is a psychoacoustic scale proposed in 1961 by researchers of the subjective human auditory properties. The original scale represents the human auditory system in 24 critical bands of hearing. Essential to the Bark (and later proposed) scale is that it is a logarithmic scale in frequency. To obtain a 17 band Bark-scale, the first 257 (unique) DFT coefficients of a 512-point DFT are combined in the following way.\n",
    "\n",
    "![PA.VII.2%28ii%29.png](graphics/PA.VII.2%28ii%29.png)\n",
    "\n",
    "The above mapping from DFT coefficient number to Bark scale band is available in the numpy array `data/bark_scale_band_id.pkl`. **Load this file into an array named `BarkScaleBandID` using the command `np.load()`. Verify the correspondence of the loaded array `BarkScaleBandID` to the above table.**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c30bb1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**For each frame, add the (magnitude of the) DFT coefficients that belong to the same Bark-scale band, yielding a array with 17 values for each frame.** These values are called Bark-scale energies. Make use of the array `BarkScaleBandID`. **Store the resulting $M \\times 17$  Bark-scale energies as a 2D array `BB`. Display the resulting Bark-scale energies using a pseudo-color plot.**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4d31fd",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**The Bark-scale energies obtained are now converted/compressed into a binary representation.** This representation has been chosen such that it is efficient for database queries and such that it is invariant to changes in loudness and some forms of degradations. The conversion/compression yields a $M \\times 16$ elements binary fingerprint in two steps:\n",
    "\n",
    "**The difference between neighboring Bark-scale energies is computed**, first in the frequency dimension and next in the temporal dimension. If $B(m,n)$ represents the 257x17 array `BB`, then the Bark-scale energy differences $e(m,n)$ are computed as follows: (for $m=0,\\cdots,M-1, n=0,\\cdots,16$):\n",
    "\n",
    "\\begin{equation}\n",
    "   e(m,n) = \\underbrace{\\underbrace{(B(m+1,n+1)-B(m+1,n))}_{\\mbox{difference between two neighboring} \\\\ \\mbox{ bark scale band energies in frame m+1}}\n",
    "   -\\underbrace{((B(m,n+1)-B(m,n))}_{\\mbox{difference between two neighboring} \\\\ \\mbox{ bark scale band energies in frame m}}}_{\\mbox{difference between two neighboring frames m+1 and m in same bark scale band n }} \n",
    "\\end{equation}\n",
    "<br>\n",
    "\n",
    "**From this $M \\times 16$ array, the values of the binary fingerprint are computed as follows:**\n",
    "\n",
    "\\begin{equation}\n",
    "   b(m,n) = \\left\\{ \\begin{array}{ll} 1 & \\mbox{if } e(m,n) \\ge 0, \\\\ \n",
    "                                      0 & \\mbox{if } e(m,n) < 0, \\end{array} \\right.\\quad\n",
    "                                      \\mbox{for } m=0,\\cdots,M-1, n=0,\\cdots,16.\n",
    "\\end{equation}\n",
    "\n",
    "**Implement the above two operations, and compute the fingerprints for the loaded music clip. Display the fingerprint using a pseudo-color plot.** An example of the computed binary fingerprint is shown in the figure.\n",
    "\n",
    "![PA.VII.2%28iii%29.png](graphics/PA.VII.2%28iii%29.png)\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8865c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617e5d22",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "You are now given a fingerprint of an unknown piece of music. **Load this $256 \\times 16$ fingerprint from the file `data/fingerprint.pkl`. Compare the loaded fingerprint with the fingerprints computed from each of the 25 music clips (listed in the above table). Count the number of differences $D$ between the fingerprint pairs, and compute the Bit Error Rate (BER)** as $ BER=\\frac{D}{256 \\times 16}$. Make sure to show the BER for each music clip.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089a17b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Please answer <i>all</i> of the following question:** From which song was the fingerprint `data/fingerprint.pkl` computed (refer to the BER values in your answer)? How well can a degraded version of the song be recognized? If you would need to build a detector that decides on basis of the BER if a song is recognized, which BER threshold would you choose for the detector and <i>why</i>?\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709a9438",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Your answer goes here.</b>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517a5b34",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px; border:none; background-color:blue;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
